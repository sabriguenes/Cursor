# Prompt Engineering

> Master the art of prompting GPT-5, reasoning models, and beyond.

This section contains comprehensive guides on OpenAI's prompt engineering best practices, based on their official 2026 documentation and real-world case studies.

---

## Guides

| Guide | Language | Description |
|-------|----------|-------------|
| [OpenAI Prompt Engineering Guide](prompt-engineering-en.md) | English | Complete 2026 guide: GPT-5, reasoning models, prompt caching, Cursor case study |
| [OpenAI Prompt Engineering Leitfaden](prompt-engineering-de.md) | Deutsch | Deutsche Version des Prompt Engineering Guides |

---

## Key Topics Covered

- **GPT-5 vs Reasoning Models** - When to use o3/o4-mini vs GPT-5.x
- **Prompt Caching** - Save up to 90% on costs, 80% on latency
- **Message Roles** - Developer, user, assistant hierarchy
- **Agentic Workflow Control** - Eagerness levels from cautious to autonomous
- **Cursor Case Study** - Real learnings from GPT-5 alpha testing
- **Frontend Development** - Recommended stack and patterns
- **Tooling** - Prompt Optimizer, Evals API, Graders

---

## Sources

All information is sourced from official OpenAI documentation:

- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [OpenAI Reasoning Best Practices](https://platform.openai.com/docs/guides/reasoning-best-practices)
- [OpenAI Prompt Caching Guide](https://platform.openai.com/docs/guides/prompt-caching)
- [OpenAI GPT-5 Prompting Guide (Cookbook)](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)

---

[Back to main README](../README.md)
